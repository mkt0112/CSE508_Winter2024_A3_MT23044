{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************     1    *****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def extract_columns(input_file, output_file):\n",
    "    # Load DataFrame from pickle file\n",
    "    df = pd.read_pickle(input_file)\n",
    "    \n",
    "    # Extract specified columns\n",
    "    extracted_df = df[['title', 'brand', 'asin']]\n",
    "    \n",
    "    # Save extracted data into another pickle file\n",
    "    extracted_df.to_pickle(output_file)\n",
    "    print(\"Selected columns saved to pickle file successfully.\")\n",
    "\n",
    "# Example usage:\n",
    "input_file = 'df_metadata.pickle'\n",
    "output_file = 'df_metadata_output.pickle'\n",
    "extract_columns(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def extract_columns(input_file, output_file, columns):\n",
    "    # Load DataFrame from pickle file\n",
    "    df = pd.read_pickle(input_file)\n",
    "    \n",
    "    # Extract specified columns\n",
    "    extracted_df = df[columns]\n",
    "    \n",
    "    # Save extracted data into another pickle file\n",
    "    extracted_df.to_pickle(output_file)\n",
    "    print(\"Selected columns saved to pickle file successfully.\")\n",
    "\n",
    "# Specify the columns you want to extract\n",
    "columns_to_extract = ['overall', 'vote', 'reviewerID', 'reviewTime', 'reviewText', 'asin']\n",
    "\n",
    "# Example usage:\n",
    "input_file = 'df_reviews.pickle'\n",
    "output_file = 'df_reviews_output.pickle'\n",
    "extract_columns(input_file, output_file, columns_to_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def combine_data(review_file, metadata_file, output_file):\n",
    "    # Load data from pickle files into DataFrames\n",
    "    df_reviews = pd.read_pickle(review_file)\n",
    "    df_metadata = pd.read_pickle(metadata_file)\n",
    "    \n",
    "    # Merge DataFrames based on 'asin' column\n",
    "    combined_df = pd.merge(df_reviews, df_metadata, on='asin', how='inner')\n",
    "    \n",
    "    # Save combined data into another pickle file\n",
    "    combined_df.to_pickle(output_file)\n",
    "    print(\"Combined data saved to pickle file successfully.\")\n",
    "\n",
    "# Specify the paths to the input pickle files and the output pickle file\n",
    "review_file = 'df_reviews_output.pickle'\n",
    "metadata_file = 'df_metadata_output.pickle'\n",
    "output_file = 'combined_data.pickle'\n",
    "\n",
    "# Call the function to combine the data\n",
    "combine_data(review_file, metadata_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************        2            **************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_headphones_data(combined_file, output_file):\n",
    "    # Load combined data from pickle file into DataFrame\n",
    "    combined_df = pd.read_pickle(combined_file)\n",
    "    \n",
    "    # Print total number of rows before extraction\n",
    "    print(\"Total number of rows before extraction:\", len(combined_df))\n",
    "    \n",
    "    # Filter data based on whether the 'title' column contains 'headphones'\n",
    "    headphones_data = combined_df[combined_df['title'].str.contains('headphones', case=False)]\n",
    "    \n",
    "    # Print total number of rows after extraction\n",
    "    print(\"Total number of rows after extraction:\", len(headphones_data))\n",
    "    \n",
    "    # Save headphones data into another pickle file\n",
    "    headphones_data.to_pickle(output_file)\n",
    "    print(\"Data for headphones saved to pickle file successfully.\")\n",
    "\n",
    "# Specify the path to the input pickle file and the output pickle file\n",
    "combined_file = 'combined_data.pickle'\n",
    "output_file = 'headphones_data.pickle'\n",
    "\n",
    "# Call the function to extract data for 'headphones' from the 'title' column\n",
    "extract_headphones_data(combined_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************    3      ***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_headphones_data(file_path):\n",
    "    # Load data from pickle file into pandas DataFrame\n",
    "    df = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Report the total number of rows for the product\n",
    "    total_rows = len(df)\n",
    "    print(\"Total number of rows for the product:\", total_rows)\n",
    "    \n",
    "    # Save the preprocessed DataFrame back to the pickle file\n",
    "    df.to_pickle('headphones_Clean_data.pickle')\n",
    "    print(\"Preprocessing completed and saved to pickle file successfully.\")\n",
    "\n",
    "# Replace 'file_path.pickle' with the actual path to your pickle file\n",
    "file_path = 'headphones_data.pickle'\n",
    "\n",
    "\n",
    "try:\n",
    "    # Perform preprocessing on the headphones data\n",
    "    preprocess_headphones_data(file_path)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please provide the correct path to the pickle file.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************  4   ***************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the preprocessed pickle file into pandas DataFrame\n",
    "file_path = 'headphones_Clean_data.pickle'\n",
    "df = pd.read_pickle(file_path)\n",
    "\n",
    "# a. Number of Reviews\n",
    "num_reviews = len(df)\n",
    "print(\"a. Number of Reviews:\", num_reviews)\n",
    "\n",
    "# b. Average Rating Score\n",
    "average_rating_score = df['overall'].mean()\n",
    "print(\"b. Average Rating Score:\", average_rating_score)\n",
    "\n",
    "# c. Number of Unique Products\n",
    "num_unique_products = df['asin'].nunique()\n",
    "print(\"c. Number of Unique Products:\", num_unique_products)\n",
    "\n",
    "# d. Number of Good Rating\n",
    "num_good_ratings = df[df['overall'] >= 3]['overall'].count()\n",
    "print(\"d. Number of Good Ratings:\", num_good_ratings)\n",
    "\n",
    "# e. Number of Bad Ratings (Set a threshold of >=3 as ‘Good’ and rest as ‘Bad’)\n",
    "num_bad_ratings = df[df['overall'] < 3]['overall'].count()\n",
    "print(\"e. Number of Bad Ratings:\", num_bad_ratings)\n",
    "\n",
    "# f. Number of Reviews corresponding to each Rating\n",
    "rating_counts = df['overall'].value_counts().sort_index()\n",
    "print(\"f. Number of Reviews corresponding to each Rating:\")\n",
    "print(rating_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************** 5 ***************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define a dictionary of common acronyms and their expanded forms\n",
    "acronyms = {\n",
    "    'lol': 'laughing out loud',\n",
    "    'brb': 'be right back',\n",
    "    'btw': 'by the way',\n",
    "    'omg': 'oh my god',\n",
    "    'idk': 'I don\\'t know',\n",
    "    'imo': 'in my opinion',\n",
    "    'imho': 'in my humble opinion',\n",
    "    'fyi': 'for your information',\n",
    "    'afaik': 'as far as I know',\n",
    "    'tbh': 'to be honest',\n",
    "    # Add more acronyms as needed\n",
    "}\n",
    "\n",
    "# Initialize WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        # Remove accented characters\n",
    "        text = unidecode(text)\n",
    "        \n",
    "        # Expand acronyms\n",
    "        for acronym, expanded_form in acronyms.items():\n",
    "            text = text.replace(acronym, expanded_form)\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Lemmatization\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        text = ''  # Convert non-string values to empty string\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing directly to the 'reviewText' column\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Save the preprocessed DataFrame to a new pickle file\n",
    "df.to_pickle('headphones_Clean_data_afterpreprocess.pickle')\n",
    "print(\"Text preprocessed and saved to pickle file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************** 6  ****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the preprocessed DataFrame from pickle file\n",
    "df = pd.read_pickle('headphones_Clean_data_afterpreprocess.pickle')\n",
    "\n",
    "# Task a: Top 20 most reviewed brands\n",
    "top_20_most_reviewed_brands = df['brand'].value_counts().head(20)\n",
    "\n",
    "# Task b: Top 20 least reviewed brands\n",
    "bottom_20_least_reviewed_brands = df['brand'].value_counts().tail(20)\n",
    "\n",
    "# Task c: Most positively reviewed headphone\n",
    "average_ratings = df.groupby('asin')['overall'].mean()\n",
    "most_positively_reviewed_headphone = average_ratings.idxmax()\n",
    "\n",
    "# Task d: Count of ratings for the product over 5 consecutive years\n",
    "df['year'] = pd.to_datetime(df['reviewTime']).dt.year\n",
    "ratings_over_5_years = df.groupby('year').size().tail(5)\n",
    "\n",
    "# Task e: Word Cloud for 'Good' and 'Bad' ratings\n",
    "good_reviews = ' '.join(df[df['overall'] >= 4]['reviewText'])\n",
    "bad_reviews = ' '.join(df[df['overall'] < 4]['reviewText'])\n",
    "\n",
    "wordcloud_good = WordCloud(width=800, height=400).generate(good_reviews)\n",
    "wordcloud_bad = WordCloud(width=800, height=400).generate(bad_reviews)\n",
    "\n",
    "# Task f: Distribution of Ratings vs. No. of Reviews\n",
    "rating_distribution = df['overall'].value_counts()\n",
    "\n",
    "# Task g: Year with maximum reviews\n",
    "year_with_max_reviews = df['year'].value_counts().idxmax()\n",
    "\n",
    "# Task h: Year with the highest number of customers\n",
    "customers_per_year = df.groupby('year')['reviewerID'].nunique()\n",
    "year_with_highest_customers = customers_per_year.idxmax()\n",
    "\n",
    "# Plotting pie chart for Task f\n",
    "rating_distribution.plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8))\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"Task a: Top 20 most reviewed brands\")\n",
    "print(top_20_most_reviewed_brands)\n",
    "print(\"\\nTask b: Top 20 least reviewed brands\")\n",
    "print(bottom_20_least_reviewed_brands)\n",
    "print(\"\\nTask c: Most positively reviewed headphone\")\n",
    "print(\"ASIN:\", most_positively_reviewed_headphone)\n",
    "print(\"\\nTask d: Count of ratings for the product over 5 consecutive years\")\n",
    "print(ratings_over_5_years)\n",
    "print(\"\\nTask e: Word Cloud for 'Good' and 'Bad' ratings\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_good, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Good Ratings')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_bad, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Bad Ratings')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTask g: Year with maximum reviews\")\n",
    "print(\"Year:\", year_with_max_reviews)\n",
    "print(\"\\nTask h: Year with the highest number of customers\")\n",
    "print(\"Year:\", year_with_highest_customers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************   7 *********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the review text\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['reviewText'])\n",
    "\n",
    "# Convert to DataFrame for easier handling (optional)\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the transformed features\n",
    "# Print the TF-IDF features\n",
    "print(\"TF-IDF Features:\")\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Save the TF-IDF features DataFrame to a CSV file\n",
    "# tfidf_df.to_csv('7.csv', index=False)\n",
    "# print(\"TF-IDF features saved to CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************  8  ************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize ratings into three classes\n",
    "def categorize_rating(rating):\n",
    "    if rating > 3:\n",
    "        return 'Good'\n",
    "    elif rating == 3:\n",
    "        return 'Average'\n",
    "    else:\n",
    "        return 'Bad'\n",
    "\n",
    "# Apply the function to create a new column 'Rating_Class'\n",
    "df['Rating_Class'] = df['overall'].apply(categorize_rating)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "# Save the updated DataFrame to a pickle file\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df.to_csv('8.csv', index=False)\n",
    "print(\"DataFrame saved to CSV file with Rating_Class column.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************  9  ******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define input feature (X) and target variable (y)\n",
    "X = df['reviewText']\n",
    "y = df['Rating_Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************  10   ***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import threading\n",
    "\n",
    "# Assuming X_train and X_test are defined elsewhere\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit and transform the review text\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(name, model):\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"Bad\", \"Average\", \"Good\"], output_dict=True)\n",
    "    \n",
    "    # Convert the report to a DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_name = f'{name}_classification_report.csv'\n",
    "    report_df.to_csv(csv_file_name)\n",
    "    print(f\"{name} report saved to {csv_file_name}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "threads = []\n",
    "for name, model in models.items():\n",
    "    thread = threading.Thread(target=train_and_evaluate_model, args=(name, model))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************  11  *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed data\n",
    "df = pd.read_pickle('headphones_Clean_data_afterpreprocess.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# First, aggregate the duplicate entries\n",
    "pivot_df = df.pivot_table(index='reviewerID', columns='asin', values='overall', aggfunc='mean')\n",
    "\n",
    "# Next, convert to a sparse CSR matrix\n",
    "# Note: You must handle NaNs here, possibly by replacing them with zeros, if that's appropriate for your use case.\n",
    "sparse_matrix = csr_matrix(pivot_df.fillna(0).values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Load data from pickle file\n",
    "filename = 'headphones_Clean_data_afterpreprocess.pickle'\n",
    "data = pd.read_pickle(filename)\n",
    "\n",
    "# Function to create user-item rating matrix\n",
    "def create_user_item_matrix(data):\n",
    "    data['reviewerID'] = data['reviewerID'].astype('category')\n",
    "    data['asin'] = data['asin'].astype('category')\n",
    "\n",
    "    data_array = np.array(list(zip(data['overall'].astype(np.int32), data['reviewerID'].cat.codes, data['asin'].cat.codes)))\n",
    "    user_item_matrix = coo_matrix((data_array[:, 0], (data_array[:, 1], data_array[:, 2])))\n",
    "    user_item_matrix = user_item_matrix.tocsr()\n",
    "    return user_item_matrix\n",
    "\n",
    "# Function to normalize ratings using min-max scaling\n",
    "def normalize_ratings(user_item_matrix):\n",
    "    # Normalize ratings to range [0, 1]\n",
    "    max_rating = user_item_matrix.max()\n",
    "    min_rating = user_item_matrix.min()\n",
    "    normalized_matrix = (user_item_matrix - min_rating) / (max_rating - min_rating)\n",
    "    return normalized_matrix\n",
    "\n",
    "# Function to calculate cosine similarity for a batch\n",
    "def calculate_similarity_batch(matrix_batch):\n",
    "    return cosine_similarity(matrix_batch)\n",
    "\n",
    "# Function to find nearest neighbors\n",
    "def find_nearest_neighbors(similarity_matrix, N):\n",
    "    return np.argsort(similarity_matrix, axis=1)[:, :-N-1:-1]\n",
    "\n",
    "# Function to predict missing values\n",
    "def predict_missing_values(user_item_matrix, similarity_matrix, nearest_neighbors):\n",
    "    predicted_matrix = np.zeros((user_item_matrix.shape[0], user_item_matrix.shape[1]))\n",
    "    for user in range(user_item_matrix.shape[0]):\n",
    "        nn_indices = nearest_neighbors[user, :len(nearest_neighbors[user])]\n",
    "        nn_ratings = user_item_matrix[nn_indices, :].toarray()\n",
    "        nn_similarities = similarity_matrix[user, nn_indices]\n",
    "        # Weighted average to predict missing values\n",
    "        predicted_matrix[user] = np.dot(nn_ratings.T, nn_similarities) / np.sum(nn_similarities)\n",
    "    return predicted_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate Mean Absolute Error (MAE)\n",
    "def calculate_mae(actual_matrix, predicted_matrix):\n",
    "    absolute_errors = np.abs(actual_matrix - predicted_matrix)\n",
    "    mae = np.mean(absolute_errors[np.where(actual_matrix != 0)])\n",
    "    return mae\n",
    "\n",
    "# Function to perform K-Folds validation with batch processing\n",
    "def k_folds_validation(data, k, N, batch_size=1000):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    mae_values = []\n",
    "\n",
    "    for train_index, val_index in kf.split(data):\n",
    "        train_data, val_data = data.iloc[train_index], data.iloc[val_index]\n",
    "\n",
    "        # Create user-item rating matrix from training set\n",
    "        user_item_matrix = create_user_item_matrix(train_data)\n",
    "\n",
    "        # Normalize ratings\n",
    "        normalized_matrix = normalize_ratings(user_item_matrix)\n",
    "\n",
    "        num_batches = (user_item_matrix.shape[0] - 1) // batch_size + 1\n",
    "\n",
    "        # Initialize predicted_matrix outside the loop\n",
    "        predicted_matrix = np.zeros_like(user_item_matrix.toarray())\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, user_item_matrix.shape[0])\n",
    "\n",
    "            batch_matrix = normalized_matrix[start_idx:end_idx]\n",
    "            batch_similarity = calculate_similarity_batch(batch_matrix)\n",
    "\n",
    "            # Find nearest neighbors only for the current batch\n",
    "            batch_nearest_neighbors = find_nearest_neighbors(batch_similarity, N)\n",
    "\n",
    "            # Predict missing values for the current batch\n",
    "            batch_predicted_matrix = predict_missing_values(batch_matrix, batch_similarity, batch_nearest_neighbors)\n",
    "\n",
    "            # Map the batch predictions back to the original user-item matrix\n",
    "            predicted_matrix[start_idx:end_idx] = batch_predicted_matrix\n",
    "\n",
    "        # Create user-item rating matrix from validation set\n",
    "        validation_user_item_matrix = create_user_item_matrix(val_data)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = calculate_mae(validation_user_item_matrix.toarray(), predicted_matrix)\n",
    "        mae_values.append(mae)\n",
    "\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    return mean_mae\n",
    "\n",
    "# Function to plot MAE against K\n",
    "def plot_mae(mae_values, k_values):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(k_values, mae_values)\n",
    "    plt.xlabel('Number of Neighbors (K)')\n",
    "    plt.ylabel('Mean Absolute Error (MAE)')\n",
    "    plt.title('MAE vs K')\n",
    "    plt.show()\n",
    "\n",
    "# Parameters\n",
    "N_values = [10, 20, 30, 40, 50]  # Number of neighbors\n",
    "K = 5  # Number of folds for K-Folds validation\n",
    "\n",
    "mae_values = []\n",
    "\n",
    "for N in N_values:\n",
    "    print(f\"Calculating MAE for N = {N}...\")\n",
    "    mean_mae = k_folds_validation(data, K, N)\n",
    "    mae_values.append(mean_mae)\n",
    "\n",
    "plot_mae(mae_values, N_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################  12   #####################33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from pickle file into DataFrame\n",
    "df = pd.read_pickle('headphones_Clean_data_afterpreprocess.pickle')\n",
    "\n",
    "# Group by 'asin' (product identifier) and calculate sum of 'overall' ratings\n",
    "product_sum_ratings = df.groupby('asin')['overall'].sum()\n",
    "\n",
    "# Sort products based on sum of ratings in descending order and select top 10\n",
    "top_10_products = product_sum_ratings.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Print the report\n",
    "print(\"**Top 10 Products by User Sum Ratings Report**\\n\")\n",
    "print(\"Product ASIN\\t\\tSum of Ratings\")\n",
    "print(\"=\"*35)\n",
    "for product_asin in top_10_products.index:\n",
    "    sum_ratings = top_10_products[product_asin]\n",
    "    print(f\"{product_asin}\\t{sum_ratings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
